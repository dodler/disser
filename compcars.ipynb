{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/dev/Documents/disser/'\n",
    "DATA_PATH = BASE_PATH + 'compcars/data/'\n",
    "IMAGE_DATA = 'image/'\n",
    "OUTPUT_DATA_PATH = BASE_PATH + 'keras_compcars_all_distinct_classes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 4455\n",
    "num_epochs = 2000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 127645 images belonging to 4455 classes.\n",
      "Found 9081 images belonging to 4455 classes.\n"
     ]
    }
   ],
   "source": [
    "train, test = helper.get_generator(OUTPUT_DATA_PATH, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xcep = InceptionV3(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xcep.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=xcep.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_acc', patience=50)\n",
    "model_cp = ModelCheckpoint('cars_cat_hinge.hdf5', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "15955/15955 [==============================] - 4586s - loss: 8.1070 - acc: 0.0012 - val_loss: 8.3843 - val_acc: 0.0020\n",
      "Epoch 2/2000\n",
      "15955/15955 [==============================] - 4583s - loss: 7.8679 - acc: 0.0020 - val_loss: 8.0392 - val_acc: 0.0020\n",
      "Epoch 3/2000\n",
      "15955/15955 [==============================] - 4618s - loss: 7.7005 - acc: 0.0024 - val_loss: 8.1143 - val_acc: 0.0025\n",
      "Epoch 4/2000\n",
      "15955/15955 [==============================] - 4605s - loss: 7.4761 - acc: 0.0042 - val_loss: 7.6673 - val_acc: 0.0044\n",
      "Epoch 5/2000\n",
      "15955/15955 [==============================] - 4600s - loss: 7.1976 - acc: 0.0068 - val_loss: 7.5067 - val_acc: 0.0077\n",
      "Epoch 6/2000\n",
      "15955/15955 [==============================] - 4602s - loss: 6.8970 - acc: 0.0101 - val_loss: 7.2286 - val_acc: 0.0096\n",
      "Epoch 7/2000\n",
      "15955/15955 [==============================] - 4596s - loss: 6.6370 - acc: 0.0145 - val_loss: 6.9537 - val_acc: 0.0131\n",
      "Epoch 8/2000\n",
      "15955/15955 [==============================] - 4587s - loss: 6.4153 - acc: 0.0198 - val_loss: 6.7492 - val_acc: 0.0183\n",
      "Epoch 9/2000\n",
      "15955/15955 [==============================] - 4586s - loss: 6.2320 - acc: 0.0246 - val_loss: 6.6727 - val_acc: 0.0250\n",
      "Epoch 10/2000\n",
      "15955/15955 [==============================] - 4587s - loss: 6.0748 - acc: 0.0306 - val_loss: 6.6298 - val_acc: 0.0282\n",
      "Epoch 11/2000\n",
      "15955/15955 [==============================] - 4586s - loss: 5.9247 - acc: 0.0367 - val_loss: 6.4011 - val_acc: 0.0357\n",
      "Epoch 12/2000\n",
      "15955/15955 [==============================] - 4600s - loss: 5.7831 - acc: 0.0434 - val_loss: 6.5328 - val_acc: 0.0341\n",
      "Epoch 13/2000\n",
      "15955/15955 [==============================] - 4593s - loss: 5.6175 - acc: 0.0517 - val_loss: 6.1392 - val_acc: 0.0467\n",
      "Epoch 14/2000\n",
      "15955/15955 [==============================] - 4610s - loss: 5.4642 - acc: 0.0594 - val_loss: 6.1656 - val_acc: 0.0570\n",
      "Epoch 15/2000\n",
      "15955/15955 [==============================] - 4614s - loss: 5.3149 - acc: 0.0680 - val_loss: 5.8844 - val_acc: 0.0644\n",
      "Epoch 16/2000\n",
      "15955/15955 [==============================] - 4653s - loss: 5.1593 - acc: 0.0776 - val_loss: 5.9164 - val_acc: 0.0714\n",
      "Epoch 17/2000\n",
      "15955/15955 [==============================] - 4615s - loss: 5.0047 - acc: 0.0885 - val_loss: 5.7753 - val_acc: 0.0740\n",
      "Epoch 18/2000\n",
      "15955/15955 [==============================] - 4630s - loss: 4.8406 - acc: 0.1004 - val_loss: 5.5612 - val_acc: 0.0869\n",
      "Epoch 19/2000\n",
      "15955/15955 [==============================] - 4613s - loss: 4.6916 - acc: 0.1118 - val_loss: 5.4580 - val_acc: 0.1035\n",
      "Epoch 20/2000\n",
      "15955/15955 [==============================] - 4610s - loss: 4.5517 - acc: 0.1233 - val_loss: 5.5529 - val_acc: 0.1014\n",
      "Epoch 21/2000\n",
      "15955/15955 [==============================] - 4594s - loss: 4.4156 - acc: 0.1347 - val_loss: 5.5479 - val_acc: 0.1104\n",
      "Epoch 22/2000\n",
      "15955/15955 [==============================] - 4602s - loss: 4.2883 - acc: 0.1479 - val_loss: 5.6016 - val_acc: 0.1064\n",
      "Epoch 23/2000\n",
      "15955/15955 [==============================] - 4603s - loss: 4.1633 - acc: 0.1606 - val_loss: 5.2915 - val_acc: 0.1308\n",
      "Epoch 24/2000\n",
      "15955/15955 [==============================] - 4611s - loss: 4.0359 - acc: 0.1739 - val_loss: 5.1942 - val_acc: 0.1351\n",
      "Epoch 25/2000\n",
      "15955/15955 [==============================] - 4594s - loss: 3.9134 - acc: 0.1857 - val_loss: 5.3486 - val_acc: 0.1370\n",
      "Epoch 26/2000\n",
      "15955/15955 [==============================] - 4589s - loss: 3.7897 - acc: 0.2015 - val_loss: 5.3867 - val_acc: 0.1377\n",
      "Epoch 27/2000\n",
      "15955/15955 [==============================] - 4584s - loss: 3.6676 - acc: 0.2153 - val_loss: 5.3955 - val_acc: 0.1404\n",
      "Epoch 28/2000\n",
      "15955/15955 [==============================] - 4584s - loss: 3.5582 - acc: 0.2297 - val_loss: 5.3754 - val_acc: 0.1471\n",
      "Epoch 29/2000\n",
      "15955/15955 [==============================] - 4582s - loss: 3.4503 - acc: 0.2437 - val_loss: 5.3667 - val_acc: 0.1590\n",
      "Epoch 30/2000\n",
      "15955/15955 [==============================] - 4587s - loss: 3.3344 - acc: 0.2580 - val_loss: 5.3173 - val_acc: 0.1586\n",
      "Epoch 31/2000\n",
      "15955/15955 [==============================] - 4592s - loss: 3.2373 - acc: 0.2727 - val_loss: 5.3746 - val_acc: 0.1590\n",
      "Epoch 32/2000\n",
      "15955/15955 [==============================] - 4602s - loss: 3.1367 - acc: 0.2883 - val_loss: 5.4464 - val_acc: 0.1582\n",
      "Epoch 33/2000\n",
      "15955/15955 [==============================] - 4609s - loss: 3.0467 - acc: 0.3016 - val_loss: 5.4697 - val_acc: 0.1681\n",
      "Epoch 34/2000\n",
      "15955/15955 [==============================] - 4590s - loss: 2.9565 - acc: 0.3155 - val_loss: 5.8127 - val_acc: 0.1655\n",
      "Epoch 35/2000\n",
      "15955/15955 [==============================] - 4586s - loss: 2.8688 - acc: 0.3286 - val_loss: 5.4699 - val_acc: 0.1718\n",
      "Epoch 36/2000\n",
      "15955/15955 [==============================] - 4582s - loss: 2.4193 - acc: 0.4101 - val_loss: 5.5912 - val_acc: 0.1838\n",
      "Epoch 37/2000\n",
      "15955/15955 [==============================] - 4584s - loss: 2.2704 - acc: 0.4348 - val_loss: 5.6636 - val_acc: 0.1884\n",
      "Epoch 38/2000\n",
      "15955/15955 [==============================] - 4591s - loss: 2.1946 - acc: 0.4516 - val_loss: 5.7762 - val_acc: 0.1870\n",
      "Epoch 39/2000\n",
      "15955/15955 [==============================] - 4585s - loss: 2.1262 - acc: 0.4626 - val_loss: 5.8010 - val_acc: 0.1840\n",
      "Epoch 40/2000\n",
      "15955/15955 [==============================] - 4585s - loss: 2.0752 - acc: 0.4730 - val_loss: 5.8625 - val_acc: 0.1870\n",
      "Epoch 41/2000\n",
      "15955/15955 [==============================] - 4581s - loss: 2.0359 - acc: 0.4817 - val_loss: 5.9805 - val_acc: 0.1845\n",
      "Epoch 42/2000\n",
      "15955/15955 [==============================] - 5032s - loss: 1.9950 - acc: 0.4885 - val_loss: 5.9424 - val_acc: 0.1862\n",
      "Epoch 43/2000\n",
      "15955/15955 [==============================] - 4727s - loss: 1.9570 - acc: 0.4986 - val_loss: 5.9990 - val_acc: 0.1841\n",
      "Epoch 44/2000\n",
      "15955/15955 [==============================] - 4609s - loss: 1.9253 - acc: 0.5036 - val_loss: 6.0504 - val_acc: 0.1863\n",
      "Epoch 45/2000\n",
      "15955/15955 [==============================] - 4571s - loss: 1.8965 - acc: 0.5096 - val_loss: 6.1790 - val_acc: 0.1820\n",
      "Epoch 46/2000\n",
      "15955/15955 [==============================] - 4570s - loss: 1.8328 - acc: 0.5245 - val_loss: 6.1914 - val_acc: 0.1811\n",
      "Epoch 47/2000\n",
      "15955/15955 [==============================] - 4567s - loss: 1.8221 - acc: 0.5258 - val_loss: 6.1758 - val_acc: 0.1868\n",
      "Epoch 48/2000\n",
      "15955/15955 [==============================] - 4569s - loss: 1.8125 - acc: 0.5277 - val_loss: 6.2361 - val_acc: 0.1811\n",
      "Epoch 49/2000\n",
      "15955/15955 [==============================] - 4570s - loss: 1.8063 - acc: 0.5279 - val_loss: 6.2198 - val_acc: 0.1862\n",
      "Epoch 50/2000\n",
      "15955/15955 [==============================] - 4587s - loss: 1.8003 - acc: 0.5287 - val_loss: 6.2073 - val_acc: 0.1834\n",
      "Epoch 51/2000\n",
      "15955/15955 [==============================] - 4633s - loss: 1.7949 - acc: 0.5320 - val_loss: 6.2618 - val_acc: 0.1817\n",
      "Epoch 52/2000\n",
      "15955/15955 [==============================] - 4638s - loss: 1.7979 - acc: 0.5298 - val_loss: 6.2172 - val_acc: 0.1856\n",
      "Epoch 53/2000\n",
      "15955/15955 [==============================] - 4629s - loss: 1.7926 - acc: 0.5304 - val_loss: 6.2810 - val_acc: 0.1821\n",
      "Epoch 54/2000\n",
      "15955/15955 [==============================] - 4623s - loss: 1.7862 - acc: 0.5334 - val_loss: 6.2867 - val_acc: 0.1815\n",
      "Epoch 55/2000\n",
      "15955/15955 [==============================] - 4633s - loss: 1.7764 - acc: 0.5344 - val_loss: 6.2517 - val_acc: 0.1851\n",
      "Epoch 56/2000\n",
      "15955/15955 [==============================] - 4654s - loss: 1.7749 - acc: 0.5367 - val_loss: 6.2547 - val_acc: 0.1825\n",
      "Epoch 57/2000\n",
      "15955/15955 [==============================] - 4626s - loss: 1.7724 - acc: 0.5358 - val_loss: 6.2340 - val_acc: 0.1844\n",
      "Epoch 58/2000\n",
      "15955/15955 [==============================] - 4624s - loss: 1.7703 - acc: 0.5352 - val_loss: 6.2672 - val_acc: 0.1835\n",
      "Epoch 59/2000\n",
      "15955/15955 [==============================] - 4613s - loss: 1.7719 - acc: 0.5363 - val_loss: 6.2814 - val_acc: 0.1848\n",
      "Epoch 60/2000\n",
      "15955/15955 [==============================] - 4621s - loss: 1.7733 - acc: 0.5366 - val_loss: 6.2782 - val_acc: 0.1830\n",
      "Epoch 61/2000\n",
      "15955/15955 [==============================] - 4646s - loss: 1.7692 - acc: 0.5370 - val_loss: 6.2183 - val_acc: 0.1854\n",
      "Epoch 62/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15955/15955 [==============================] - 4613s - loss: 1.7680 - acc: 0.5367 - val_loss: 6.3306 - val_acc: 0.1826\n",
      "Epoch 63/2000\n",
      "15955/15955 [==============================] - 4597s - loss: 1.7667 - acc: 0.5363 - val_loss: 6.3299 - val_acc: 0.1830\n",
      "Epoch 64/2000\n",
      "15955/15955 [==============================] - 4589s - loss: 1.7753 - acc: 0.5345 - val_loss: 6.2845 - val_acc: 0.1831\n",
      "Epoch 65/2000\n",
      "15955/15955 [==============================] - 4584s - loss: 1.7725 - acc: 0.5353 - val_loss: 6.2338 - val_acc: 0.1849\n",
      "Epoch 66/2000\n",
      "15955/15955 [==============================] - 4583s - loss: 1.7687 - acc: 0.5374 - val_loss: 6.3232 - val_acc: 0.1832\n",
      "Epoch 67/2000\n",
      "15955/15955 [==============================] - 4584s - loss: 1.7701 - acc: 0.5379 - val_loss: 6.2207 - val_acc: 0.1851\n",
      "Epoch 68/2000\n",
      "15955/15955 [==============================] - 4588s - loss: 1.7681 - acc: 0.5385 - val_loss: 6.2396 - val_acc: 0.1846\n",
      "Epoch 69/2000\n",
      "15955/15955 [==============================] - 4596s - loss: 1.7698 - acc: 0.5373 - val_loss: 6.2678 - val_acc: 0.1838\n",
      "Epoch 70/2000\n",
      "15955/15955 [==============================] - 4608s - loss: 1.7670 - acc: 0.5372 - val_loss: 6.2702 - val_acc: 0.1827\n",
      "Epoch 71/2000\n",
      "15955/15955 [==============================] - 4624s - loss: 1.7617 - acc: 0.5376 - val_loss: 6.2384 - val_acc: 0.1889\n",
      "Epoch 72/2000\n",
      "15955/15955 [==============================] - 4618s - loss: 1.7678 - acc: 0.5370 - val_loss: 6.3231 - val_acc: 0.1809\n",
      "Epoch 73/2000\n",
      " 7633/15955 [=============>................] - ETA: 2361s - loss: 1.7646 - acc: 0.5408"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    callbacks=[early_stop, model_cp, reduce_lr],\n",
    "    generator=train, \n",
    "    epochs=num_epochs, \n",
    "    steps_per_epoch=int(train.samples / batch_size),\n",
    "    validation_data=test,\n",
    "    validation_steps=int(test.samples / batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
